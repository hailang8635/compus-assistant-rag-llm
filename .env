# 复制本文件为 .env（与 README 一样放在仓库根目录），启动时会自动读取

# ======= LLM Provider =======
# ollama (local) | deepseek (remote)
LLM_PROVIDER=ollama

# ======= Ollama (Local) =======
OLLAMA_BASE_URL=http://localhost:11434
LLM_MODEL=qwen2.5:7b
EMBED_MODEL=nomic-embed-text

# ======= DeepSeek (Optional) =======
DEEPSEEK_BASE_URL=https://api.deepseek.com/chat/completions
DEEPSEEK_API_KEY=sk-xxxdb
# LLM_MODEL=deepseek-chat

# ======= RAG =======
RAG_TOP_K=5
# 命中阈值：太低会带入不相关内容；太高可能“宁可不命中”
# 0.45
RAG_MIN_SCORE=0.40
# 关键词重叠过滤：要求 RAG chunk 至少包含多少个来自问题的关键词片段
RAG_MIN_KEYWORD_HITS=1

# ======= Logging =======
LOG_LEVEL=DEBUG
LOG_LLM_IO=true
LOG_LLM_MAX_CHARS=4000
LOG_MSG_MAX_CHARS=500


